# -*- coding: utf-8 -*-
"""ComVisAssignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QdIJyT0Ta4ea0122AB_rnycjpNr3DdAE
"""

pip install opencv-python mediapipe numpy

import cv2
import mediapipe as mp
import numpy as np
import json
import os

#Output Directory
output_dir = 'output'
os.makedirs(output_dir, exist_ok=True)

# Initialize MediaPipe Pose
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)
mp_drawing = mp.solutions.drawing_utils

# Load video
video_path = 'input.mp4'  # replace with the downloaded video path
cap = cv2.VideoCapture(video_path)

# Get video properties
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = int(cap.get(cv2.CAP_PROP_FPS))

# Define output video
output_path = os.path.join(output_dir, 'annotated_video.mp4')
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

# metrics tracking
frame_count = 0
elbow_angles = []
spine_leans = []
head_knee_alignments = []
foot_directions = []

def calculate_angle(a, b, c):
    a = np.array(a)
    b = np.array(b)
    c = np.array(c)
    ba = a - b
    bc = c - b
    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)
    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))
    return np.degrees(angle)

def calculate_spine_lean(hip, shoulder):
    hip = np.array(hip)
    shoulder = np.array(shoulder)
    vector = shoulder - hip
    vertical = np.array([0, -1])
    cosine_angle = np.dot(vector, vertical) / (np.linalg.norm(vector) * np.linalg.norm(vertical) + 1e-6)
    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))
    return np.degrees(angle)

def calculate_head_knee_alignment(head, knee):
    head = np.array(head)
    knee = np.array(knee)
    return np.linalg.norm(head[:2] - knee[:2])

def calculate_foot_direction(ankle, knee):
    ankle = np.array(ankle)
    knee = np.array(knee)
    vector = ankle - knee
    angle = np.arctan2(vector[1], vector[0])
    return np.degrees(angle)

from google.colab.patches import cv2_imshow

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    frame_count += 1
    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(image_rgb)

    if results.pose_landmarks:
        landmarks = results.pose_landmarks.landmark

        # Extract coordinates safely
        def get_point(index):
            lm = landmarks[index]
            return [int(lm.x * width), int(lm.y * height)]

        try:
            shoulder = get_point(mp_pose.PoseLandmark.LEFT_SHOULDER.value)
            elbow = get_point(mp_pose.PoseLandmark.LEFT_ELBOW.value)
            wrist = get_point(mp_pose.PoseLandmark.LEFT_WRIST.value)
            hip = get_point(mp_pose.PoseLandmark.LEFT_HIP.value)
            knee = get_point(mp_pose.PoseLandmark.LEFT_KNEE.value)
            ankle = get_point(mp_pose.PoseLandmark.LEFT_ANKLE.value)
            head = get_point(mp_pose.PoseLandmark.NOSE.value)

            # Compute metrics
            elbow_angle = calculate_angle(shoulder, elbow, wrist)
            spine_lean = calculate_spine_lean(hip, shoulder)
            head_knee_alignment = calculate_head_knee_alignment(head, knee)
            foot_direction = calculate_foot_direction(ankle, knee)

            elbow_angles.append(elbow_angle)
            spine_leans.append(spine_lean)
            head_knee_alignments.append(head_knee_alignment)
            foot_directions.append(foot_direction)

            # Draw skeleton
            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

            # Display metrics
            cv2.putText(frame, f'Elbow: {int(elbow_angle)}°', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)
            cv2.putText(frame, f'Spine: {int(spine_lean)}°', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)
            cv2.putText(frame, f'Head-Knee Dist: {int(head_knee_alignment)}', (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)

            # Feedback cues
            feedback = []
            if elbow_angle > 150:
                feedback.append("✅ Good elbow elevation")
            if head_knee_alignment > 50:
                feedback.append("❌ Head not over front knee")
            for idx, msg in enumerate(feedback):
                cv2.putText(frame, msg, (10, 120 + idx*30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)

        except:
            cv2.putText(frame, "⚠ Pose not fully detected", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2)

    out.write(frame)
    cv2_imshow(frame)


    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
out.release()
cv2.destroyAllWindows()

# Final Evaluation
def average(values):
    return sum(values) / len(values) if values else 0

evaluation = {
    "Footwork": round(10 - abs(average(foot_directions)) / 10, 1),
    "Head Position": round(10 - average(head_knee_alignments) / 10, 1),
    "Swing Control": round(average(elbow_angles) / 180 * 10, 1),
    "Balance": round(10 - average(spine_leans) / 10, 1),
    "Follow-through": round(average(elbow_angles) / 180 * 10, 1),
    "Feedback": {
        "Footwork": "Improve toe alignment for better balance.",
        "Head Position": "Keep head aligned over knee during follow-through.",
        "Swing Control": "Maintain consistent elbow angle throughout.",
        "Balance": "Reduce excessive spine lean to improve control.",
        "Follow-through": "Focus on smooth elbow extension after impact."
    }
}

with open(os.path.join(output_dir, 'evaluation.json'), 'w') as f:
    json.dump(evaluation, f, indent=4)

print("Analysis complete. Results saved in /output/")





